{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b771329",
   "metadata": {},
   "source": [
    "# <center>Data Exploration</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a42d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from tqdm.notebook import tqdm\n",
    "import parselmouth\n",
    "from feature_extraction_utils import *\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e208132",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'tess'\n",
    "tess_data_path = \"TESS Toronto emotional speech set data/\"\n",
    "TESS_path = os.path.abspath(tess_data_path)\n",
    "\n",
    "dir_list_TESS = os.listdir(TESS_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925653b",
   "metadata": {},
   "source": [
    "## TESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447f1f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OAF_Fear',\n",
       " 'OAF_Pleasant_surprise',\n",
       " 'OAF_Sad',\n",
       " 'OAF_angry',\n",
       " 'OAF_disgust',\n",
       " 'OAF_happy',\n",
       " 'OAF_neutral',\n",
       " 'YAF_angry',\n",
       " 'YAF_disgust',\n",
       " 'YAF_fear',\n",
       " 'YAF_happy',\n",
       " 'YAF_neutral',\n",
       " 'YAF_pleasant_surprised',\n",
       " 'YAF_sad']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = os.listdir(TESS_path)\n",
    "dir_list.sort()\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "emotion = []\n",
    "\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(TESS_path + \"/\" + i)\n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "            emotion.append('female_angry')\n",
    "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "            emotion.append('female_disgust')\n",
    "        elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "            emotion.append('female_fear')\n",
    "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "            emotion.append('female_happy')\n",
    "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "            emotion.append('female_neutral')                                \n",
    "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "            emotion.append('female_surprise')               \n",
    "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "            emotion.append('female_sad')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(TESS_path + \"/\" + i + \"/\" + f)\n",
    "\n",
    "TESS_df = pd.DataFrame(emotion, columns = ['label'])\n",
    "TESS_df['source'] = 'TESS'\n",
    "TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "TESS_df.label.value_counts()\n",
    "TESS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29bb0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_df.to_csv('TESS_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6906e",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de4c30",
   "metadata": {},
   "source": [
    "### Extract feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1968d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_set_1(sound_filepath):\n",
    "    sound = parselmouth.Sound(sound_filepath)\n",
    "    df = pd.DataFrame()\n",
    "    attributes = {}\n",
    "\n",
    "    intensity_attributes = get_intensity_attributes(sound)[0]\n",
    "    pitch_attributes = get_pitch_attributes(sound)[0]\n",
    "    attributes.update(intensity_attributes)\n",
    "    attributes.update(pitch_attributes)\n",
    "\n",
    "    hnr_attributes = get_harmonics_to_noise_ratio_attributes(sound)[0]\n",
    "    gne_attributes = get_glottal_to_noise_ratio_attributes(sound)[0]\n",
    "    attributes.update(hnr_attributes)\n",
    "    attributes.update(gne_attributes)\n",
    "\n",
    "    df['local_jitter'] = None\n",
    "    df['local_shimmer'] = None\n",
    "    df.at[0, 'local_jitter'] = get_local_jitter(sound)\n",
    "    df.at[0, 'local_shimmer'] = get_local_shimmer(sound)\n",
    "\n",
    "    spectrum_attributes = get_spectrum_attributes(sound)[0]\n",
    "    attributes.update(spectrum_attributes)\n",
    "\n",
    "    formant_attributes = get_formant_attributes(sound)[0]\n",
    "    attributes.update(formant_attributes)\n",
    "    \n",
    "    '''lfcc_matrix, mfcc_matrix = get_lfcc(sound), get_mfcc(sound)\n",
    "    df['lfcc'] = None\n",
    "    df['mfcc'] = None\n",
    "    df.at[0, 'lfcc'] = lfcc_matrix\n",
    "    df.at[0, 'mfcc'] = mfcc_matrix\n",
    "\n",
    "    delta_mfcc_matrix = get_delta(mfcc_matrix)\n",
    "    delta_delta_mfcc_matrix = get_delta(delta_mfcc_matrix)\n",
    "    df['delta_mfcc'] = None\n",
    "    df['delta_delta_mfcc'] = None\n",
    "    df.at[0, 'delta_mfcc'] = delta_mfcc_matrix\n",
    "    df.at[0, 'delta_delta_mfcc'] = delta_delta_mfcc_matrix'''\n",
    "\n",
    "    for attribute in attributes:\n",
    "        df.at[0, attribute] = attributes[attribute]\n",
    "    \n",
    "    df.at[0, 'sound_filepath'] = sound_filepath\n",
    "    rearranged_columns = df.columns.tolist()[-1:] + df.columns.tolist()[:-1]\n",
    "    df = df[rearranged_columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cff69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_filepaths = TESS_df['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5282f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_list = []\n",
    "source = []\n",
    "label = []\n",
    "for i in tqdm(range(len(sound_filepaths))):\n",
    "    source.append(TESS_df['source'][i])\n",
    "    label.append(TESS_df['label'][i])\n",
    "    all_df_list.append(extract_feature_set_1(sound_filepaths[i]))\n",
    "all_df = pd.concat(all_df_list)\n",
    "all_df['source'] = source\n",
    "all_df['class'] = label\n",
    "all_df.rename(columns={'sound_filepath':'path'}, inplace=True)\n",
    "all_df.to_csv(dataset_name+'_feature_set_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0828917",
   "metadata": {},
   "source": [
    "### Extract feature set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = []\n",
    "zcr = []\n",
    "spectral_centroid = []\n",
    "spectral_bandwidth = []\n",
    "spectral_contrast = []\n",
    "spectral_rolloff = []\n",
    "ptch = []\n",
    "path = []\n",
    "source = []\n",
    "label = []\n",
    "\n",
    "minF0_list = []\n",
    "maxF0_list = []\n",
    "avgF0_list = []\n",
    "min_intensity_list = []\n",
    "max_intensity_list = []\n",
    "avg_intensity_list = []\n",
    "jitter_list = []\n",
    "shimmer_list = []\n",
    "hnr_list = []\n",
    "import math\n",
    "\n",
    "for i in tqdm(range(len(TESS_df))):\n",
    "    y, sr = librosa.load(TESS_df['path'][i])\n",
    "    S, phase = librosa.magphase(librosa.stft(y))\n",
    "    rms.append(librosa.feature.rms(S=S).mean())\n",
    "    zcr.append(librosa.feature.zero_crossing_rate(y).mean())\n",
    "    spectral_centroid.append(librosa.feature.spectral_centroid(y, sr=sr)[0].mean())\n",
    "    spectral_bandwidth.append(librosa.feature.spectral_bandwidth(y, sr=sr)[0].mean())\n",
    "    spectral_contrast.append(librosa.feature.spectral_contrast(y, sr=sr)[0].mean())\n",
    "    spectral_rolloff.append(librosa.feature.spectral_rolloff(y+0.01, sr=sr)[0].mean())\n",
    "    path.append(TESS_df['path'][i])\n",
    "    source.append(TESS_df['source'][i])\n",
    "    label.append(TESS_df['label'][i])\n",
    "    \n",
    "    file_name = (TESS_df['path'][i]).split(\".\")[0]\n",
    "    input_sound = parselmouth.Sound(TESS_df['path'][i])\n",
    "    # extracts the duration\n",
    "    duration = input_sound.get_total_duration()\n",
    "    # extracts the pitch metrics\n",
    "    pitch = call(input_sound, \"To Pitch\", 0.0, 75.0, 600.0)\n",
    "    minF0 = call(pitch, \"Get minimum\", 0.0, duration, \"Hertz\", \"Parabolic\")\n",
    "    maxF0 = call(pitch, \"Get maximum\", 0.0, duration, \"Hertz\", \"Parabolic\")\n",
    "    avgF0 = call(pitch, \"Get mean\", 0.0, duration, \"Hertz\")\n",
    "    # extracts the intensity metrics\n",
    "    intensity = call(input_sound, \"To Intensity\", 75.0, 0.0)\n",
    "    min_intensity = intensity.get_minimum()\n",
    "    max_intensity = intensity.get_maximum()\n",
    "    avg_intensity = intensity.get_average()\n",
    "    # extracts jitter\n",
    "    point_process = call(input_sound, \"To PointProcess (periodic, cc)\", 75.0, 600.0)\n",
    "    jitter = call(point_process, \"Get jitter (local)\", 0.0, 0.0, 0.0001, 0.02, 1.3)\n",
    "    # extracts shimmer\n",
    "    shimmer = call(\n",
    "            [input_sound, point_process],\n",
    "            \"Get shimmer (local)\",\n",
    "            0,\n",
    "            0,\n",
    "            0.0001,\n",
    "            0.02,\n",
    "            1.3,\n",
    "            1.6,\n",
    "        )\n",
    "    # extracts HNR\n",
    "    harmonicity = call(input_sound, \"To Harmonicity (cc)\", 0.01, 75.0, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    \n",
    "    minF0_list.append(round(round(minF0 if not math.isnan(minF0) else 0, 3),))\n",
    "    maxF0_list.append(round(round(maxF0 if not math.isnan(maxF0) else 0, 3),))\n",
    "    avgF0_list.append(round(round(avgF0 if not math.isnan(avgF0) else 0, 3),))\n",
    "    min_intensity_list.append(round(round(min_intensity if not math.isnan(min_intensity) else 0, 3),))\n",
    "    max_intensity_list.append(round(round(max_intensity if not math.isnan(max_intensity) else 0, 3),))\n",
    "    avg_intensity_list.append(round(round(avg_intensity if not math.isnan(avg_intensity) else 0, 3),))\n",
    "    jitter_list.append(round(round(jitter if not math.isnan(jitter) else 0, 3),))\n",
    "    shimmer_list.append(round(round(shimmer if not math.isnan(shimmer) else 0, 3),))\n",
    "    hnr_list.append(round(round(hnr if not math.isnan(hnr) else 0, 3),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30657869",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = pd.DataFrame({'rms':rms, 'zcr':zcr, 'spectral_centroid':spectral_centroid, \n",
    "                       'spectral_bandwidth':spectral_bandwidth, 'spectral_contrast':spectral_contrast,\n",
    "                       'spectral_rolloff':spectral_rolloff,'minF0':minF0_list,\n",
    "                        'maxF0':maxF0_list,'avgF0':avgF0_list,'min_intensity':min_intensity_list,\n",
    "                        'max_intensity':max_intensity_list,'avg_intensity':avg_intensity_list,\n",
    "                        'jitter':jitter_list,'shimmer':shimmer_list,'hnr':hnr_list,\n",
    "                        'path':path,'source':source, 'class':label})\n",
    "data_f.to_csv(dataset_name+'_feature_set_2.csv', index=False)\n",
    "data_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa90a2",
   "metadata": {},
   "source": [
    "### Extract feature set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15458ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_freq(freqs, path, source, label):\n",
    "    mean = np.mean(freqs)\n",
    "    std = np.std(freqs) \n",
    "    maxv = np.amax(freqs) \n",
    "    minv = np.amin(freqs) \n",
    "    median = np.median(freqs)\n",
    "    skew = scipy.stats.skew(freqs)\n",
    "    kurt = scipy.stats.kurtosis(freqs)\n",
    "    q1 = np.quantile(freqs, 0.25)\n",
    "    q3 = np.quantile(freqs, 0.75)\n",
    "    mode = scipy.stats.mode(freqs)[0][0]\n",
    "    iqr = scipy.stats.iqr(freqs)\n",
    "    return [path, mean, std, maxv, minv, median, skew, kurt, q1, q3, mode, iqr, source, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list_fft = []\n",
    "all_list_mfcc = []\n",
    "for i in tqdm(range(len(TESS_df))):\n",
    "    y, sr = librosa.load(TESS_df['path'][i])\n",
    "    fft = np.fft.fftfreq(y.size)\n",
    "    all_list_fft.append(describe_freq(fft, TESS_df['path'][i], TESS_df['source'][i], TESS_df['label'][i]))\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y)\n",
    "    all_list_mfcc.append(describe_freq(mfcc, TESS_df['path'][i], TESS_df['source'][i], TESS_df['label'][i]))\n",
    "    \n",
    "data_features_fft = pd.DataFrame(all_list_fft, columns=['path','mean_fft', 'std_fft', 'maxv_fft', 'minv_fft', 'median_fft', 'skew_fft', 'kurt_fft', 'q1_fft', 'q3_fft', 'mode_fft', 'iqr_fft', 'source', 'class'])\n",
    "data_features_mfcc = pd.DataFrame(all_list_mfcc, columns=['path','mean_mfcc', 'std_mfcc', 'maxv_mfcc', 'minv_mfcc', 'median_mfcc', 'skew_mfcc', 'kurt_mfcc', 'q1_mfcc', 'q3_mfcc', 'mode_mfcc', 'iqr_mfcc', 'source', 'class'])\n",
    "\n",
    "data_features_fft.to_csv(dataset_name+'_feature_set_3_fft.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = []\n",
    "kurt = []\n",
    "mode = []\n",
    "for i in tqdm(range(len(data_features_mfcc))):\n",
    "    skew.append(data_features_mfcc['skew_mfcc'][i].mean())\n",
    "    kurt.append(data_features_mfcc['kurt_mfcc'][i].mean())\n",
    "    mode.append(data_features_mfcc['mode_mfcc'][i].mean())\n",
    "data_features_mfcc['skew_mfcc'] = skew\n",
    "data_features_mfcc['kurt_mfcc'] = kurt\n",
    "data_features_mfcc['mode_mfcc'] = mode\n",
    "data_features_mfcc.to_csv(dataset_name+'_feature_set_3_mfcc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a16593",
   "metadata": {},
   "source": [
    "# **Aggregate all extratced features into one dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exfeat_1 = pd.read_csv(dataset_name+'_feature_set_1.csv')\n",
    "data_exfeat_1.drop(columns=['path','source', 'class'],inplace=True)\n",
    "data_exfeat_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ed118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exfeat_2 = pd.read_csv(dataset_name+'_feature_set_2.csv')\n",
    "data_exfeat_2.drop(columns=['path','source', 'class'],inplace=True)\n",
    "data_exfeat_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c01fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exfeat_3_fft = pd.read_csv(dataset_name+'_feature_set_3_fft.csv')\n",
    "data_exfeat_3_fft.drop(columns=['path','source', 'class'],inplace=True)\n",
    "data_exfeat_3_fft.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bcac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exfeat_3_mfcc = pd.read_csv(dataset_name+'_feature_set_3_mfcc.csv')\n",
    "#data_handcrafted_3.drop(columns=['path','source', 'class'],inplace=True)\n",
    "data_exfeat_3_mfcc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f142fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_exfeat = pd.concat([data_exfeat_1, data_exfeat_2,\n",
    "                                  data_exfeat_3_fft, data_exfeat_3_mfcc], axis=1)\n",
    "all_data_exfeat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb348ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_exfeat.to_csv(f'all_handcrafted_data_{dataset_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
